# ğŸ“š Naive Bayes Text Classifier  
**Python | NLP | Machine Learning From Scratch**

This project implements **Binary** and **Multinomial Naive Bayes classifiers** from scratch (without scikit-learn) to classify:

- SMS Spam vs Ham (Binary)
- BBC News Articles (5-Class Classification)

The goal is to understand ML fundamentals by manually computing priors, likelihoods, smoothing, and log-probabilities.

---

## ğŸš€ Features
- Full preprocessing pipeline  
- Vocabulary creation  
- Laplace smoothing  
- Binary NB (presence-based)  
- Multinomial NB (frequency-based)  
- Manual prediction logic  
- Confusion matrix visualization  
- Top indicative words per class  
- Achieved **97.8% accuracy** on both datasets  

---

## ğŸ“ Datasets Used
- **SMS Spam Collection (UCI)**  
- **BBC News Articles (Kaggle)**  

---

## ğŸ§  How Naive Bayes Works
The classifier uses:

**Posterior:**  
